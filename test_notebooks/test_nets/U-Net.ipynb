{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9548957a-b075-4f5f-97c1-e662c0b0e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf Dataset Trained_Model                   # Remove existing directory\n",
    "!pip install -U gdown --pre >/dev/null          # Install gdown to download file from GDrive\n",
    "!gdown 1u4WJLjYrbZHwdvFOHQXJqDTtco6F5hJ-        # Download dataset from GDrive by file ID\n",
    "!unzip -q Dataset.zip; rm Dataset.zip           # Extract the dataset zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737aa3c7-bd5e-4ae5-a5c2-8b2adfab85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "IMAGES_PATH = 'Dataset/Images/'\n",
    "MASKS_PATH  = 'Dataset/Masks/'\n",
    "TEST_PATH   = 'Dataset/Test_Images/'\n",
    "\n",
    "# Number of images to use (Larger the number, more RAM required)\n",
    "N_IMAGES = 1500\n",
    "\n",
    "# Imread each image and save to an array\n",
    "\n",
    "sat_imgs = os.listdir(IMAGES_PATH)\n",
    "msk_imgs = os.listdir(MASKS_PATH)\n",
    "sat_imgs.sort(), msk_imgs.sort()\n",
    "\n",
    "images = []\n",
    "for image in sat_imgs[:N_IMAGES]:\n",
    "    data = imread(IMAGES_PATH + image)\n",
    "    images.append(data)\n",
    "\n",
    "masks = []\n",
    "for mask in msk_imgs[:N_IMAGES]:\n",
    "    data = imread(MASKS_PATH + mask)\n",
    "    data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
    "    data = np.expand_dims(data, axis=-1)\n",
    "    masks.append(data)\n",
    "\n",
    "images = np.stack(images)\n",
    "masks = np.stack(masks) / 255\n",
    "\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.2, random_state=2)\n",
    "\n",
    "pred_images = sample(sat_imgs, 4)\n",
    "pred_masks  = []\n",
    "for mask_name in pred_images:\n",
    "    mask_name = mask_name.replace('_sat.jpg', '_mask.png')\n",
    "    pred_masks.append(mask_name)\n",
    "\n",
    "del images, masks\n",
    "\n",
    "print(\"Training Set\")\n",
    "print(train_images.shape)\n",
    "print(train_masks.shape)\n",
    "print(\"Testing Set\")\n",
    "print(test_images.shape)\n",
    "print(test_masks.shape)\n",
    "\n",
    "!rm -rf epochs Trained_Model; mkdir epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d77e0-faec-4549-abca-170104f0a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c116e83-02b8-4fb5-83e4-eda38ec3b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def soft_dice_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d5d4c1-6d0f-46cf-95d5-cf2e687fe55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, Activation, concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def unet_model():\n",
    "    input_layer = Input(shape=(512, 512, 3))\n",
    "\n",
    "# Encoder\n",
    "  # Down 1\n",
    "    x = Conv2D(64, 2, activation='relu', padding='same') (input_layer)\n",
    "    x = Conv2D(64, 2, activation='relu', padding='same') (x)\n",
    "    skip_1 = x\n",
    "    x = MaxPooling2D(2, strides=2) (x)\n",
    "    x = Dropout(0.3) (x)\n",
    "\n",
    "  # Down 2\n",
    "    x = Conv2D(128, 2, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(128, 2, activation='relu', padding='same') (x)\n",
    "    skip_2 = x\n",
    "    x = MaxPooling2D(2, strides=2) (x)\n",
    "    x = Dropout(0.5) (x)\n",
    "\n",
    "  # Down 3\n",
    "    x = Conv2D(256, 2, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(256, 2, activation='relu', padding='same') (x)\n",
    "    skip_3 = x\n",
    "    x = MaxPooling2D(2, strides=2) (x)\n",
    "    x = Dropout(0.5) (x)\n",
    "\n",
    "  # Down 4\n",
    "    x = Conv2D(512, 2, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(512, 2, activation='relu', padding='same') (x)\n",
    "    skip_4 = x\n",
    "    x = MaxPooling2D(2, strides=2) (x)\n",
    "    x = Dropout(0.5) (x)\n",
    "\n",
    "\n",
    "\n",
    "  # Lowest\n",
    "    x = Conv2D(1024, 2, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(1024, 2, activation='relu', padding='same') (x)\n",
    "\n",
    "\n",
    "\n",
    "# Decoder\n",
    "  # Upsample 4\n",
    "    x = Conv2DTranspose(512, kernel_size=2, strides=2) (x)\n",
    "    x = concatenate(([skip_4, x]))\n",
    "    x = Dropout(0.5) (x)\n",
    "    x = Conv2D(512, 2, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(512, 2, activation='relu', padding='same') (x)\n",
    "\n",
    "  # Upsample 3\n",
    "    x = Conv2DTranspose(256, kernel_size=2, strides=2) (x)\n",
    "    x = concatenate(([skip_3, x]))\n",
    "    x = Dropout(0.5) (x)\n",
    "    x = Conv2D(256, 2, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(256, 2, activation='relu', padding='same') (x)\n",
    "\n",
    "  # Upsample 2\n",
    "    x = Conv2DTranspose(128, kernel_size=2, strides=2) (x)\n",
    "    x = concatenate(([skip_2, x]))\n",
    "    x = Dropout(0.5) (x)\n",
    "    x = Conv2D(128, 2, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(128, 2, activation='relu', padding='same') (x)\n",
    "\n",
    "  # Upsample 1\n",
    "    x = Conv2DTranspose(64, kernel_size=2, strides=2) (x)\n",
    "    x = concatenate(([skip_1, x]))\n",
    "    x = Dropout(0.5) (x)\n",
    "    x = Conv2D(64, 2, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(64, 2, activation='relu', padding='same') (x)\n",
    "\n",
    "    x = Conv2D(1, 1, kernel_initializer='he_normal') (x)\n",
    "\n",
    "    output_layer = (Activation('sigmoid'))(x)\n",
    "\n",
    "    model = Model(input_layer, output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2011bdf-130e-4c82-858d-33232671b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from IPython.display import clear_output\n",
    "from skimage.io import imread, imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow as tf\n",
    "\n",
    "model_path = \"./Final_Model/Unet-Model.h5\"\n",
    "evals = []\n",
    "scores = []\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(model_path, monitor=\"val_loss\", mode=\"min\", save_best_only = True, verbose=1)\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, restore_best_weights = True)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4)\n",
    "\n",
    "def model_status(epoch, accu, val_accu, loss, val_loss):\n",
    "    [model_loss, accuracy, tp, fp, tn, fn, precision, recall] = model.evaluate(test_images, test_masks)\n",
    "    f1_score = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    evals.append(accuracy)\n",
    "    scores.append(f1_score)\n",
    "\n",
    "    f = plt.figure(figsize = (24, 16))\n",
    "    gs = f.add_gridspec(4, 6)\n",
    "    f.suptitle(f'Epoch: {epoch}', x=0.5, y=0.02)\n",
    "    titles = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(0,4):\n",
    "        data = [imread(f'Dataset/Images/{pred_images[i]}')]\n",
    "        input_img = imread(f'Dataset/Images/{pred_images[i]}')\n",
    "        mask_img = imread(f'Dataset/Masks/{pred_masks[i]}')\n",
    "        test_data = np.asarray([input_img])\n",
    "        output = model.predict(test_data, verbose=0)[0][:,:,0]\n",
    "        data += [mask_img, output]\n",
    "        for j in range(0,3):  \n",
    "            f.add_subplot(gs[i, j])\n",
    "            if j%2==0:\n",
    "                plt.imshow(data[j], cmap='gray')\n",
    "            else:\n",
    "                plt.imshow(data[j])\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title(titles[j])\n",
    "\n",
    "    ax = f.add_subplot(gs[0:2, 3:6])\n",
    "    ax.tick_params(axis=\"y\",direction=\"in\", pad=-25)\n",
    "    ax.text(.5,.95,'Model Accuracy', horizontalalignment='center', transform=ax.transAxes, weight='bold')\n",
    "    plt.plot(accu)\n",
    "    plt.plot(val_accu)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training Accuracy', 'Validation accuracy'], loc='lower right')\n",
    "    \n",
    "    ax = f.add_subplot(gs[2:4, 3:6])\n",
    "    ax.tick_params(axis=\"y\",direction=\"in\", pad=-25)\n",
    "    ax.text(.5,.95,'Model Loss', horizontalalignment='center', transform=ax.transAxes, weight='bold')\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "    \n",
    "    plt.savefig(f'epochs/{epoch}.png')\n",
    "    plt.show()\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.accu = []\n",
    "        self.val_accu = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.accu.append(logs.get(\"accuracy\"))\n",
    "        self.val_accu.append(logs.get(\"val_accuracy\"))\n",
    "        self.loss.append(logs.get(\"loss\"))\n",
    "        self.val_loss.append(logs.get(\"val_loss\"))\n",
    "        clear_output(wait=True)\n",
    "        model_status(epoch, self.accu, self.val_accu, self.loss, self.val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40d61f-6611-4031-8a68-5af420a75cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = unet_model()\n",
    "    metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf6bf4-9181-44dd-8ca1-ed54aaa153ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 32\n",
    "adam = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "\n",
    "model.compile(optimizer=adam, loss=soft_dice_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445b1a8-4d55-4129-a95b-516b6cd62dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_masks,\n",
    "                    validation_split = 0.1,\n",
    "                    epochs = EPOCHS,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    callbacks = [checkpointer, DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c3a64b-56d2-414d-8923-a3fb5c1c1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4770c2-93d6-4a1c-b842-1da96a359ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images = sample(sat_imgs, 4)\n",
    "pred_masks  = []\n",
    "for mask_name in pred_images:\n",
    "    mask_name = mask_name.replace('_sat.jpg', '_mask.png')\n",
    "    pred_masks.append(mask_name)\n",
    "\n",
    "f = plt.figure(figsize = (15, 12), constrained_layout=True)\n",
    "gs = f.add_gridspec(5, 6)\n",
    "titles = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "for i in range(0,4):\n",
    "    data = [imread(f'Dataset/Images/{pred_images[i]}')]\n",
    "    input_img = imread(f'Dataset/Images/{pred_images[i]}')\n",
    "    mask_img = imread(f'Dataset/Masks/{pred_masks[i]}')\n",
    "    test_data = np.asarray([input_img])\n",
    "    output = model.predict(test_data, verbose=0)[0][:,:,0]\n",
    "    final_out = input_img\n",
    "    for xi in range(len(output)):\n",
    "        for yi in range(len(output[xi])):\n",
    "            if output[xi][yi] > 0.1:\n",
    "                final_out[xi][yi] = [255, 255, 0]\n",
    "    data += [mask_img, final_out]\n",
    "    for j in range(0,3):  \n",
    "        f.add_subplot(gs[i, j])\n",
    "        plt.imshow(data[j])\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(titles[j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc3b65-f3af-44e8-be83-e043fcc463b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with 800 samples\n",
    "images = []\n",
    "for image in sat_imgs[4000:4800]:\n",
    "    data = imread(IMAGES_PATH + image)\n",
    "    images.append(data)\n",
    "\n",
    "masks = []\n",
    "for mask in msk_imgs[4000:4800]:\n",
    "    data = imread(MASKS_PATH + mask)\n",
    "    data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
    "    data = np.expand_dims(data, axis=-1)\n",
    "    masks.append(data)\n",
    "\n",
    "images = np.stack(images)\n",
    "masks = np.stack(masks) / 255\n",
    "\n",
    "evals = model.evaluate(images, masks)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
