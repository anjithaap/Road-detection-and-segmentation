{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebf8a78672",
   "metadata": {
    "id": "EXY5LUQ8EowE"
   },
   "outputs": [],
   "source": [
    "!rm -rf Dataset Trained_Model                   # Remove existing directory\n",
    "!pip install -U gdown --pre >/dev/null          # Install gdown to download file from GDrive\n",
    "!gdown 1u4WJLjYrbZHwdvFOHQXJqDTtco6F5hJ-        # Download dataset from GDrive by file ID\n",
    "!unzip -q Dataset.zip; rm Dataset.zip           # Extract the dataset zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28821af7d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "IMAGES_PATH = 'Dataset/Images/'\n",
    "MASKS_PATH  = 'Dataset/Masks/'\n",
    "TEST_PATH   = 'Dataset/Test_Images/'\n",
    "\n",
    "# Number of images to use (Larger the number, more RAM required)\n",
    "N_IMAGES = 1500\n",
    "\n",
    "# Imread each image and save to an array\n",
    "\n",
    "sat_imgs = os.listdir(IMAGES_PATH)\n",
    "msk_imgs = os.listdir(MASKS_PATH)\n",
    "sat_imgs.sort(), msk_imgs.sort()\n",
    "\n",
    "images = []\n",
    "for image in sat_imgs[:N_IMAGES]:\n",
    "    data = imread(IMAGES_PATH + image)\n",
    "    images.append(data)\n",
    "\n",
    "masks = []\n",
    "for mask in msk_imgs[:N_IMAGES]:\n",
    "    data = imread(MASKS_PATH + mask)\n",
    "    data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
    "    data = np.expand_dims(data, axis=-1)\n",
    "    masks.append(data)\n",
    "\n",
    "images = np.stack(images)\n",
    "masks = np.stack(masks) / 255\n",
    "\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.2, random_state=2)\n",
    "\n",
    "pred_images = sample(os.listdir(IMAGES_PATH), 4)\n",
    "pred_masks  = []\n",
    "for mask_name in pred_images:\n",
    "    mask_name = mask_name.replace('_sat.jpg', '_mask.png')\n",
    "    pred_masks.append(mask_name)\n",
    "\n",
    "del images, masks\n",
    "\n",
    "print(\"Training Set\")\n",
    "print(train_images.shape)\n",
    "print(train_masks.shape)\n",
    "print(\"Testing Set\")\n",
    "print(test_images.shape)\n",
    "print(test_masks.shape)\n",
    "\n",
    "!rm -rf epochs Trained_Model; mkdir epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154c1cd3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31f71a4f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def soft_dice_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904bea3b329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, Activation, add\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def FCN8():\n",
    "    img_input = Input(shape=(512, 512, 3))\n",
    "\n",
    "# Block 1\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same') (img_input)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same') (x)\n",
    "    x = MaxPooling2D(2, strides=2) (x)\n",
    "    x = Dropout(0.3) (x)\n",
    "\n",
    "# Block 2\n",
    "    x = Conv2D(128, 3, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(128, 3, activation='relu', padding='same') (x)\n",
    "    x = MaxPooling2D(2, strides=2) (x)\n",
    "    x = Dropout(0.5) (x)\n",
    "\n",
    "# Block 3\n",
    "    x = Conv2D(256, 3, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(256, 3, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(256, 3, activation='relu', padding='same') (x)\n",
    "    x = MaxPooling2D(2, strides=2) (x)\n",
    "    x = Dropout(0.5) (x)\n",
    "\n",
    "    skip1 = Conv2D(256, 3, activation='relu', padding='same') (x)\n",
    "\n",
    "# Block 4\n",
    "    x = Conv2D(512, 3, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(512, 3, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(512, 3, activation='relu', padding='same') (x)\n",
    "    x = MaxPooling2D(2, strides=2) (x)\n",
    "    x = Dropout(0.5) (x)\n",
    "\n",
    "    skip2 = Conv2D(256, 3, activation='relu', padding='same') (x)\n",
    "    skip2 = Conv2DTranspose(256, kernel_size=2, strides=2) (skip2)\n",
    "\n",
    "# Block 5\n",
    "    x = Conv2D(512, 3, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(512, 3, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(512, 3, activation='relu', padding='same') (x)\n",
    "    x = MaxPooling2D(2, strides=2) (x)\n",
    "    x = Dropout(0.5) (x)\n",
    "\n",
    "\n",
    "    x = Conv2D(4096 , (7, 7) , activation='relu' , padding='same') (x)\n",
    "    x = Conv2D(4096 , (1, 1) , activation='relu' , padding='same') (x)\n",
    "\n",
    "    x = Conv2D(256, 3, activation='relu', padding='same') (x)\n",
    "    x = Conv2DTranspose(256, kernel_size=2, strides=2) (x)\n",
    "    x = Conv2DTranspose(256, kernel_size=2, strides=2) (x)\n",
    "\n",
    "    x = add([skip1, skip2, x])\n",
    "\n",
    "    x = Conv2DTranspose(128, kernel_size=2, kernel_initializer='he_normal', strides=2) (x)\n",
    "    x = Conv2DTranspose(32, kernel_size=2, kernel_initializer='he_normal', strides=2) (x)\n",
    "    x = Conv2DTranspose(8, kernel_size=2, kernel_initializer='he_normal', strides=2) (x)\n",
    "\n",
    "    x = Conv2D(1, 1, kernel_initializer='he_normal') (x)\n",
    "    x = (Activation('sigmoid'))(x)\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb1438494f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from IPython.display import clear_output\n",
    "from skimage.io import imread, imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow as tf\n",
    "\n",
    "model_path = \"./Final_Model/FCNN-8-Model.h5\"\n",
    "evals = []\n",
    "scores = []\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(model_path, monitor=\"val_loss\", mode=\"min\", save_best_only = True, verbose=1)\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, restore_best_weights = True)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4)\n",
    "\n",
    "def model_status(epoch, accu, val_accu, loss, val_loss):\n",
    "    [loss, accuracy, tp, fp, tn, fn, precision, recall] = model.evaluate(test_images, test_masks)\n",
    "    f1_score = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    evals.append(accuracy)\n",
    "    scores.append(f1_score)\n",
    "\n",
    "    f = plt.figure(figsize = (24, 16))\n",
    "    gs = f.add_gridspec(4, 6)\n",
    "    f.suptitle(f'Epoch: {epoch}', x=0.5, y=0.02)\n",
    "    titles = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(0,4):\n",
    "        data = [imread(f'Dataset/Images/{pred_images[i]}')]\n",
    "        input_img = imread(f'Dataset/Images/{pred_images[i]}')\n",
    "        mask_img = imread(f'Dataset/Masks/{pred_masks[i]}')\n",
    "        test_data = np.asarray([input_img])\n",
    "        output = model.predict(test_data, verbose=0)[0][:,:,0]\n",
    "        data += [mask_img, output]\n",
    "        for j in range(0,3):  \n",
    "            f.add_subplot(gs[i, j])\n",
    "            plt.imshow(data[j])\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title(titles[j])\n",
    "\n",
    "    ax = f.add_subplot(gs[0:2, 3:6])\n",
    "    ax.tick_params(axis=\"y\",direction=\"in\", pad=-25)\n",
    "    ax.text(.5,.95,'Model Accuracy', horizontalalignment='center', transform=ax.transAxes, weight='bold')\n",
    "    plt.plot(accu)\n",
    "    plt.plot(val_accu)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training Accuracy', 'Validation accuracy'], loc='lower right')\n",
    "    \n",
    "    ax = f.add_subplot(gs[2:4, 3:6])\n",
    "    ax.tick_params(axis=\"y\",direction=\"in\", pad=-25)\n",
    "    ax.text(.5,.95,'Model Loss', horizontalalignment='center', transform=ax.transAxes, weight='bold')\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "    \n",
    "    plt.savefig(f'epochs/{epoch}.png')\n",
    "    plt.show()\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.accu = []\n",
    "        self.val_accu = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.accu.append(logs.get(\"accuracy\"))\n",
    "        self.val_accu.append(logs.get(\"val_accuracy\"))\n",
    "        self.loss.append(logs.get(\"loss\"))\n",
    "        self.val_loss.append(logs.get(\"val_loss\"))\n",
    "        clear_output(wait=True)\n",
    "        model_status(epoch, self.accu, self.val_accu, self.loss, self.val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac13e45e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = FCN8()\n",
    "    metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41441ad5dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 150\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 56\n",
    "adam = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "\n",
    "model.compile(optimizer=adam, loss=soft_dice_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b918be385e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_masks,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs = EPOCHS,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    callbacks = [checkpointer, DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4655b57-0df7-4aaa-b329-6590e27cae77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a19d8b-aa8c-426a-bd46-9b08460f9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images = sample(os.listdir(IMAGES_PATH), 4)\n",
    "pred_masks  = []\n",
    "for mask_name in pred_images:\n",
    "    mask_name = mask_name.replace('_sat.jpg', '_mask.png')\n",
    "    pred_masks.append(mask_name)\n",
    "\n",
    "f = plt.figure(figsize = (15, 12), constrained_layout=True)\n",
    "gs = f.add_gridspec(5, 6)\n",
    "titles = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "for i in range(0,4):\n",
    "    data = [imread(f'Dataset/Images/{pred_images[i]}')]\n",
    "    input_img = imread(f'Dataset/Images/{pred_images[i]}')\n",
    "    mask_img = imread(f'Dataset/Masks/{pred_masks[i]}')\n",
    "    test_data = np.asarray([input_img])\n",
    "    output = model.predict(test_data, verbose=0)[0][:,:,0]\n",
    "    final_out = input_img\n",
    "    for xi in range(len(output)):\n",
    "        for yi in range(len(output[xi])):\n",
    "            if output[xi][yi] > 0.1:\n",
    "                final_out[xi][yi] = [255, 255, 0]\n",
    "    data += [mask_img, final_out]\n",
    "    for j in range(0,3):  \n",
    "        f.add_subplot(gs[i, j])\n",
    "        plt.imshow(data[j])\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(titles[j])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "FCN-8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
