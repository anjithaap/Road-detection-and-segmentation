{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb935184-60f1-499c-83d5-cdeac24da27c",
   "metadata": {
    "id": "EXY5LUQ8EowE"
   },
   "outputs": [],
   "source": [
    "!rm -rf Dataset Trained_Model                   # Remove existing directory\n",
    "!pip install -U gdown --pre >/dev/null          # Install gdown to download file from GDrive\n",
    "!gdown 1u4WJLjYrbZHwdvFOHQXJqDTtco6F5hJ-        # Download dataset from GDrive by file ID\n",
    "!unzip -q Dataset.zip; rm Dataset.zip           # Extract the dataset zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203dee54-a255-42ff-84c9-4efd384ce329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "IMAGES_PATH = 'Dataset/Images/'\n",
    "MASKS_PATH  = 'Dataset/Masks/'\n",
    "TEST_PATH   = 'Dataset/Test_Images/'\n",
    "\n",
    "# Number of images to use (Larger the number, more RAM required)\n",
    "N_IMAGES = 1500\n",
    "\n",
    "# Imread each image and save to an array\n",
    "\n",
    "sat_imgs = os.listdir(IMAGES_PATH)\n",
    "msk_imgs = os.listdir(MASKS_PATH)\n",
    "sat_imgs.sort(), msk_imgs.sort()\n",
    "\n",
    "images = []\n",
    "for image in (sat_imgs[:N_IMAGES]):\n",
    "    data = imread(IMAGES_PATH + image)\n",
    "    images.append(data)\n",
    "\n",
    "masks = []\n",
    "for mask in (msk_imgs[:N_IMAGES]):\n",
    "    data = imread(MASKS_PATH + mask)\n",
    "    data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
    "    data = np.expand_dims(data, axis=-1)\n",
    "    masks.append(data)\n",
    "\n",
    "images = np.stack(images)\n",
    "masks = np.stack(masks) / 255\n",
    "\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.2, random_state=2)\n",
    "del images, masks\n",
    "\n",
    "print(\"Training Set\")\n",
    "print(train_images.shape)\n",
    "print(train_masks.shape)\n",
    "print(\"Testing Set\")\n",
    "print(test_images.shape)\n",
    "print(test_masks.shape)\n",
    "\n",
    "!rm -rf epochs Trained_Model; mkdir epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f67e1b-b2f4-420b-9a2c-aaa864f40b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be99870-a250-477b-9e2d-c35f59f7394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def soft_dice_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38106965-8af4-443b-817a-4a5ecc95e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def FCN32():\n",
    "\n",
    "    img_input = Input(shape=(512, 512, 3))\n",
    "\n",
    "    x = Conv2D(64, 3, activation='relu', name='Block-1_Conv-1', padding='same') (img_input)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.1) (x)\n",
    "    x = Conv2D(64, 3, activation='relu', name='Block-1_Conv-2', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.1) (x)\n",
    "    x = MaxPooling2D(2, strides=2, name='P-1') (x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, 3, activation='relu', name='Block-2_Conv-1', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = Conv2D(128, 3, activation='relu', name='Block-2_Conv-2', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = MaxPooling2D(2, strides=2, name='P-2') (x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, 3, activation='relu', name='Block-3_Conv-1', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.3) (x)\n",
    "    x = Conv2D(256, 3, activation='relu', name='Block-3_Conv-2', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.3) (x)\n",
    "    x = Conv2D(256, 3, activation='relu', name='Block-3_Conv-3', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.3) (x)\n",
    "    x = MaxPooling2D(2, strides=2, name='P-3') (x)\n",
    "    \n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-4_Conv-1', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.3) (x)\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-4_Conv-2', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.3) (x)\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-4_Conv-3', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.3) (x)\n",
    "    x = MaxPooling2D(2, strides=2, name='P-4') (x)\n",
    "    \n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-5_Conv-1', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-5_Conv-2', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-5_Conv-3', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = MaxPooling2D(2, strides=2, name='P-5') (x)\n",
    "\n",
    "\n",
    "    x = Conv2D(4096 , (7, 7) , activation='relu' , name='Fully-Connected-1', padding='same') (x)\n",
    "    x = Conv2D(4096 , (1, 1) , activation='relu' , name='Fully-Connected-2', padding='same') (x)\n",
    "\n",
    "    \n",
    "    # Upsampling Layers\n",
    "\n",
    "    x = Conv2DTranspose(128, kernel_size=2, kernel_initializer='he_normal', name='Upsample_2x', strides=2) (x)\n",
    "    x = Conv2DTranspose( 64, kernel_size=2, kernel_initializer='he_normal', name='Upsample_4x', strides=2) (x)\n",
    "    x = Conv2DTranspose(128, kernel_size=2, kernel_initializer='he_normal', name='Upsample_8x', strides=2) (x)\n",
    "    x = Conv2DTranspose( 64, kernel_size=2, kernel_initializer='he_normal', name='Upsample_16x', strides=2) (x)\n",
    "    x = Conv2DTranspose( 32, kernel_size=2, kernel_initializer='he_normal', name='Upsample_32x', strides=2) (x)\n",
    "\n",
    "    x = Conv2D(1, 1, kernel_initializer='he_normal') (x)\n",
    "    x = Dropout(0.1) (x)\n",
    "\n",
    "    x = (Activation('sigmoid'))(x)\n",
    "    model = Model(img_input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a07a9-760f-41c0-adb6-dd059c9bd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = FCN32()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0146ae4-a619-4eff-8cf9-4f1c254be056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from IPython.display import clear_output\n",
    "from skimage.io import imread, imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow as tf\n",
    "\n",
    "model_path = \"./Trained_Model/Road_Model.h5\"\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(model_path, monitor=\"val_loss\", mode=\"min\", save_best_only = True, verbose=1)\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, restore_best_weights = True)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4)\n",
    "\n",
    "def model_status(epoch, accu, val_accu, loss, val_loss):\n",
    "    test_path1 = 'Dataset/Test_Images/11740_sat.jpg'\n",
    "    test_path2 = 'Dataset/Test_Images/112348_sat.jpg'\n",
    "    test_path3 = 'Dataset/Test_Images/115172_sat.jpg'\n",
    "    test_path4 = 'Dataset/Test_Images/173947_sat.jpg'\n",
    "\n",
    "    test_img1  = np.asarray([imread(test_path1)])\n",
    "    test_img2  = np.asarray([imread(test_path2)])\n",
    "    test_img3  = np.asarray([imread(test_path3)])\n",
    "    test_img4  = np.asarray([imread(test_path4)])\n",
    "\n",
    "    f = plt.figure(figsize = (10, 14))\n",
    "    gs = f.add_gridspec(4, 4)\n",
    "    f.suptitle(f'Epoch: {epoch}', x=0.5, y=0.02)\n",
    "\n",
    "    \n",
    "    f.add_subplot(gs[0, 0])\n",
    "    plt.imshow(imread(test_path1), cmap='gray')\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[0, 1])\n",
    "    plt.imshow(model.predict(test_img1, verbose=1)[0][:,:,0], cmap='gray')\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(gs[1, 0])\n",
    "    plt.imshow(imread(test_path2), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[1, 1])\n",
    "    plt.imshow(model.predict(test_img2, verbose=1)[0][:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(gs[2, 0])\n",
    "    plt.imshow(imread(test_path3), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[2, 1])\n",
    "    plt.imshow(model.predict(test_img3, verbose=1)[0][:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(gs[3, 0])\n",
    "    plt.imshow(imread(test_path3), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[3, 1])\n",
    "    plt.imshow(model.predict(test_img4, verbose=1)[0][:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    f.add_subplot(gs[0:2, 2:4])\n",
    "    plt.plot(accu)\n",
    "    plt.plot(val_accu)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training Accuracy', 'Validation accuracy'], loc='lower right')\n",
    "    \n",
    "    f.add_subplot(gs[2:4, 2:4])\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "    \n",
    "    plt.savefig(f'epochs/{epoch}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.accu = []\n",
    "        self.val_accu = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.accu.append(logs.get(\"accuracy\"))\n",
    "        self.val_accu.append(logs.get(\"val_accuracy\"))\n",
    "        self.loss.append(logs.get(\"loss\"))\n",
    "        self.val_loss.append(logs.get(\"val_loss\"))\n",
    "        clear_output(wait=True)\n",
    "        model_status(epoch, self.accu, self.val_accu, self.loss, self.val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e1b046-770a-4842-9f4e-b14329861da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 56\n",
    "adam = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "\n",
    "model.compile(optimizer=adam, loss=soft_dice_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a8814-873d-4110-bba7-7b448c3256c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_masks,\n",
    "                    validation_data = (test_images, test_masks),\n",
    "                    epochs = EPOCHS,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    callbacks = [checkpointer, DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1125f6-8844-4d35-8d2e-5511650fcc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "accuracy = history_fig.add_subplot(1,2,1)\n",
    "imgplot = plt.plot(history.history['accuracy'])\n",
    "imgplot = plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Accuracy', 'Validation accuracy'], loc='upper right')\n",
    "accuracy.set_title(\"Epoch Accuracy\")\n",
    "\n",
    "loss = history_fig.add_subplot(1,2,2)\n",
    "imgplot = plt.plot(history.history['loss'])\n",
    "imgplot = plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "loss.set_title(\"Epoch Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f588f-2afd-4dc6-a8dc-cfbf864977f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage.io import imshow\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "model = load_model(\"./Trained_Model/Road_Model.h5\", custom_objects={'soft_dice_loss': soft_dice_loss, 'iou_coef': iou_coef})\n",
    "predictions = model.predict(test_images, verbose=1)\n",
    "thresh_val = 0.1\n",
    "predicton_threshold = (predictions > thresh_val).astype(np.uint8)\n",
    "\n",
    "\n",
    "ix = random.randint(0, len(predictions))\n",
    "num_samples = 3\n",
    "\n",
    "f = plt.figure(figsize = (12, 10))\n",
    "for i in range(1, num_samples*4, 4):\n",
    "    ix = random.randint(0, len(predictions))\n",
    "\n",
    "    f.add_subplot(num_samples, 4, i)\n",
    "    imshow(test_images[ix])\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(num_samples, 4, i+1)\n",
    "    imshow(np.squeeze(test_masks[ix][:,:,0]))\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(num_samples, 4, i+2)\n",
    "    imshow(np.squeeze(predictions[ix][:,:,0]))\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "test_path = 'Dataset/Images/100892_sat.jpg'\n",
    "mask_path = 'Dataset/Masks/100892_mask.png'\n",
    "test_img  = np.asarray([imread(test_path)])\n",
    "\n",
    "f = plt.figure(figsize = (12, 10))\n",
    "f.add_subplot(1,3,1)\n",
    "imshow(imread(test_path))\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "f.add_subplot(1,3,2)\n",
    "imshow(imread(mask_path))\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.axis('off')\n",
    "\n",
    "f.add_subplot(1,3,3)\n",
    "imshow(model.predict(test_img, verbose=1)[0][:,:,0])\n",
    "plt.title(\"Prtedicted Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcd80b-9966-41f0-a1d2-239bfce5c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf *.mp4 *.avi\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "video_name = 'video.avi'\n",
    "epochs = os.listdir('epochs')\n",
    "frame = cv2.imread('epochs/1.png')\n",
    "height, width, layers = frame.shape\n",
    "video = cv2.VideoWriter(video_name, 0, 15, (width,height))\n",
    "for i in range(1, len(epochs)):\n",
    "    video.write(cv2.imread(f'epochs/{i}.png'))\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n",
    "\n",
    "!ffmpeg -i video.avi -c:v copy -c:a copy output.mp4\n",
    "!ffmpeg -i output.mp4 -vcodec libx265 -crf 28 Epochs.mp4\n",
    "!rm output.mp4\n",
    "!printf \"Video file ready : Epochs.mp4\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "FCN-32.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
