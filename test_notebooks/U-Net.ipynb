{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9548957a-b075-4f5f-97c1-e662c0b0e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf Dataset Trained_Model                   # Remove existing directory\n",
    "!pip install -U gdown --pre >/dev/null          # Install gdown to download file from GDrive\n",
    "!gdown 1u4WJLjYrbZHwdvFOHQXJqDTtco6F5hJ-        # Download dataset from GDrive by file ID\n",
    "!unzip -q Dataset.zip; rm Dataset.zip           # Extract the dataset zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737aa3c7-bd5e-4ae5-a5c2-8b2adfab85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "IMAGES_PATH = 'Dataset/Images/'\n",
    "MASKS_PATH  = 'Dataset/Masks/'\n",
    "TEST_PATH   = 'Dataset/Test_Images/'\n",
    "\n",
    "# Number of images to use (Larger the number, more RAM required)\n",
    "N_IMAGES = 1500\n",
    "\n",
    "# Imread each image and save to an array\n",
    "\n",
    "sat_imgs = os.listdir(IMAGES_PATH)\n",
    "msk_imgs = os.listdir(MASKS_PATH)\n",
    "sat_imgs.sort(), msk_imgs.sort()\n",
    "\n",
    "images = []\n",
    "for image in sat_imgs[:N_IMAGES]:\n",
    "    data = imread(IMAGES_PATH + image)\n",
    "    images.append(data)\n",
    "\n",
    "masks = []\n",
    "for mask in msk_imgs[:N_IMAGES]:\n",
    "    data = imread(MASKS_PATH + mask)\n",
    "    data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
    "    data = np.expand_dims(data, axis=-1)\n",
    "    masks.append(data)\n",
    "\n",
    "images = np.stack(images)\n",
    "masks = np.stack(masks) / 255\n",
    "\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.2, random_state=2)\n",
    "\n",
    "pred_images = sample(os.listdir(IMAGES_PATH), 4)\n",
    "pred_masks  = []\n",
    "for mask_name in pred_images:\n",
    "    mask_name = mask_name.replace('_sat.jpg', '_mask.png')\n",
    "    pred_masks.append(mask_name)\n",
    "\n",
    "del images, masks\n",
    "\n",
    "print(\"Training Set\")\n",
    "print(train_images.shape)\n",
    "print(train_masks.shape)\n",
    "print(\"Testing Set\")\n",
    "print(test_images.shape)\n",
    "print(test_masks.shape)\n",
    "\n",
    "!rm -rf epochs Trained_Model; mkdir epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d77e0-faec-4549-abca-170104f0a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c116e83-02b8-4fb5-83e4-eda38ec3b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def soft_dice_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d5d4c1-6d0f-46cf-95d5-cf2e687fe55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def double_conv_block(x, n_filters):\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "    return x\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "    f = double_conv_block(x, n_filters)\n",
    "    p = layers.MaxPool2D(2)(f)\n",
    "    p = layers.Dropout(0.3)(p)\n",
    "    return f, p\n",
    "\n",
    "def upsample_block(x, conv_features, n_filters):\n",
    "    x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "    x = layers.concatenate([x, conv_features])\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = double_conv_block(x, n_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet_model():\n",
    "\n",
    "    inputs = layers.Input(shape=(512,512,3))\n",
    "\n",
    "    f1, p1 = downsample_block(inputs, 64)\n",
    "    f2, p2 = downsample_block(p1, 128)\n",
    "    f3, p3 = downsample_block(p2, 256)\n",
    "    f4, p4 = downsample_block(p3, 512)\n",
    "\n",
    "    bottleneck = double_conv_block(p4, 1024)\n",
    "\n",
    "    u6 = upsample_block(bottleneck, f4, 512)\n",
    "    u7 = upsample_block(u6, f3, 256)\n",
    "    u8 = upsample_block(u7, f2, 128)\n",
    "    u9 = upsample_block(u8, f1, 64)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u9)\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "    return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2011bdf-130e-4c82-858d-33232671b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from IPython.display import clear_output\n",
    "from skimage.io import imread, imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow as tf\n",
    "\n",
    "model_path = \"./Trained_Model/Road_Model.h5\"\n",
    "evals = []\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(model_path, monitor=\"val_loss\", mode=\"min\", save_best_only = True, verbose=1)\n",
    "earlystopper = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, restore_best_weights = True)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4)\n",
    "\n",
    "def model_status(epoch, accu, val_accu, loss, val_loss):\n",
    "    evals.append(model.evaluate(test_images, test_masks)[1])\n",
    "\n",
    "    pred_img_path1 = IMAGES_PATH + pred_images[0]; pred_msk_path1 = MASKS_PATH + pred_masks[0]\n",
    "    pred_img_path2 = IMAGES_PATH + pred_images[1]; pred_msk_path2 = MASKS_PATH + pred_masks[1]\n",
    "    pred_img_path3 = IMAGES_PATH + pred_images[2]; pred_msk_path3 = MASKS_PATH + pred_masks[2]\n",
    "    pred_img_path4 = IMAGES_PATH + pred_images[3]; pred_msk_path4 = MASKS_PATH + pred_masks[3]\n",
    "\n",
    "    test_img1  = np.asarray([imread(pred_img_path1)])\n",
    "    test_img2  = np.asarray([imread(pred_img_path2)])\n",
    "    test_img3  = np.asarray([imread(pred_img_path3)])\n",
    "    test_img4  = np.asarray([imread(pred_img_path4)])\n",
    "\n",
    "    f = plt.figure(figsize = (24, 16))\n",
    "    gs = f.add_gridspec(5, 6)\n",
    "    f.suptitle(f'Epoch: {epoch}', x=0.5, y=0.02)\n",
    "\n",
    "    \n",
    "    f.add_subplot(gs[0, 0])\n",
    "    plt.imshow(imread(pred_img_path1), cmap='gray')\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[0, 1])\n",
    "    plt.imshow(imread(pred_msk_path1), cmap='gray')\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[0, 2])\n",
    "    plt.imshow(model.predict(test_img1, verbose=1)[0][:,:,0], cmap='gray')\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    f.add_subplot(gs[1, 0])\n",
    "    plt.imshow(imread(pred_img_path2), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[1, 1])\n",
    "    plt.imshow(imread(pred_msk_path2), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[1, 2])\n",
    "    plt.imshow(model.predict(test_img2, verbose=1)[0][:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(gs[2, 0])\n",
    "    plt.imshow(imread(pred_img_path3), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[2, 1])\n",
    "    plt.imshow(imread(pred_msk_path3), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[2, 2])\n",
    "    plt.imshow(model.predict(test_img3, verbose=1)[0][:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(gs[3, 0])\n",
    "    plt.imshow(imread(pred_img_path4), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[3, 1])\n",
    "    plt.imshow(imread(pred_msk_path4), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(gs[3, 2])\n",
    "    plt.imshow(model.predict(test_img4, verbose=1)[0][:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(gs[0:2, 3:6])\n",
    "    plt.plot(accu)\n",
    "    plt.plot(val_accu)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.legend(['Training Accuracy', 'Validation accuracy'], loc='lower right')\n",
    "    \n",
    "    f.add_subplot(gs[3:5, 3:6])\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "    \n",
    "    plt.savefig(f'epochs/{epoch}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.accu = []\n",
    "        self.val_accu = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.accu.append(logs.get(\"accuracy\"))\n",
    "        self.val_accu.append(logs.get(\"val_accuracy\"))\n",
    "        self.loss.append(logs.get(\"loss\"))\n",
    "        self.val_loss.append(logs.get(\"val_loss\"))\n",
    "        clear_output(wait=True)\n",
    "        model_status(epoch, self.accu, self.val_accu, self.loss, self.val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40d61f-6611-4031-8a68-5af420a75cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = build_unet_model()\n",
    "    metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.TruePositives(name='tp'),\n",
    "    tf.keras.metrics.FalsePositives(name='fp'),\n",
    "    tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "    tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf6bf4-9181-44dd-8ca1-ed54aaa153ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 32\n",
    "adam = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "\n",
    "model.compile(optimizer=adam, loss=soft_dice_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445b1a8-4d55-4129-a95b-516b6cd62dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_masks,\n",
    "                    validation_split = 0.1,\n",
    "                    epochs = EPOCHS,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    callbacks = [checkpointer, DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c3a64b-56d2-414d-8923-a3fb5c1c1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870f99bd-9f79-4e2d-81a1-f54eb15679dd",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f2b750-74ec-4f40-a388-879af448f67b",
   "metadata": {},
   "source": [
    "# Road Detection using Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c55e75d-f13d-4189-a744-4827ed00651d",
   "metadata": {},
   "source": [
    "## Load trained model and required objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d57fd-de03-451f-9a41-a164d93b3330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def soft_dice_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "model = load_model(\"./Trained_Model/Road_Model.h5\", custom_objects={'soft_dice_loss': soft_dice_loss, 'iou_coef': iou_coef})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6320adf4-6bf1-4b81-bfe1-52564e5afac4",
   "metadata": {},
   "source": [
    "## Select a random input image and generate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35274510-0139-4a82-96cd-e214d34fdb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from skimage.io import imread\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "input_img = imread(f'Dataset/Images/{sample(os.listdir(\"Dataset/Images\"),1)[0]}')\n",
    "test_data = np.asarray([input_img])\n",
    "output = model.predict(test_data, verbose=0)[0][:,:,0]\n",
    "\n",
    "for xi in range(len(output)):\n",
    "    for yi in range(len(output[xi])):\n",
    "        if output[xi][yi] > 0.1:\n",
    "            input_img[xi][yi] = [255, 255, 0]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.imshow(input_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
