{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b546885a-c94f-43c9-9902-234fd2c168e3",
   "metadata": {},
   "source": [
    "# Road Segmentation with FCN-8 powered by Google TPU\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/anjithaap/Road-detection-and-segmentation/blob/master/notebooks/GPU/FCN-8.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a30757-4630-47fa-95c7-018465933a0e",
   "metadata": {
    "id": "CtCwQRg5EowD",
    "tags": []
   },
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed95a36-7e63-4af7-a0b5-9911d28794d5",
   "metadata": {
    "id": "EXY5LUQ8EowE"
   },
   "outputs": [],
   "source": [
    "!rm -rf Dataset Trained_Model                   # Remove existing directory\n",
    "!pip install -U gdown --pre >/dev/null          # Install gdown to download file from GDrive\n",
    "!gdown 1u4WJLjYrbZHwdvFOHQXJqDTtco6F5hJ-        # Download dataset from GDrive by file ID\n",
    "!unzip -q Dataset.zip; rm Dataset.zip           # Extract the dataset zip file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa41d92b-4fd5-4616-a108-9f79a28b88cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d31a6c1-1f62-475a-b7a6-28821af7d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IMAGES_PATH = 'Dataset/Images/'\n",
    "MASKS_PATH  = 'Dataset/Masks/'\n",
    "TEST_PATH   = 'Dataset/Test_Images/'\n",
    "\n",
    "# Number of images to use (Larger the number, more RAM required)\n",
    "N_IMAGES = 1500\n",
    "\n",
    "# Imread each image and save to an array\n",
    "\n",
    "sat_imgs = os.listdir(IMAGES_PATH)\n",
    "msk_imgs = os.listdir(MASKS_PATH)\n",
    "sat_imgs.sort(), msk_imgs.sort()\n",
    "\n",
    "images = []\n",
    "for image in (sat_imgs[:N_IMAGES]):\n",
    "    data = imread(IMAGES_PATH + image)\n",
    "    images.append(data)\n",
    "\n",
    "masks = []\n",
    "for mask in (msk_imgs[:N_IMAGES]):\n",
    "    data = imread(MASKS_PATH + mask)\n",
    "    data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
    "    data = np.expand_dims(data, axis=-1)\n",
    "    masks.append(data)\n",
    "\n",
    "images = np.stack(images)\n",
    "masks = np.stack(masks)\n",
    "\n",
    "\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.2, random_state=10)\n",
    "del images, masks\n",
    "print(\"Training Set\")\n",
    "print(train_images.shape)\n",
    "print(train_masks.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Testing set\")\n",
    "print(test_images.shape)\n",
    "print(test_masks.shape)\n",
    "\n",
    "!rm -rf epochs Trained_Model; mkdir epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc9fe04-78e5-4825-a94c-1d6f477fc6b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Define Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c2343-1103-4b17-b8f2-c31f71a4f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def soft_dice_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75e2d4-5642-4faf-bfd0-694e7998159e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Define FCN-8 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1beebe8-7ff5-44d5-b198-904bea3b329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, Activation, BatchNormalization, add\n",
    "from keras.models import Model\n",
    "\n",
    "def FCN8():\n",
    "\n",
    "    img_input = Input(shape=(512, 512, 3))\n",
    "\n",
    "    x = Conv2D(64, 3, activation='relu', name='Block-1_Conv-1', padding='same') (img_input)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = Conv2D(64, 3, activation='relu', name='Block-1_Conv-2', padding='same') (x)\n",
    "    x = BatchNormalization() (x)\n",
    "    x = MaxPooling2D(2, strides=2, name='Pooling-1') (x)\n",
    "    skip1 = x\n",
    "    skip1 = Conv2D(1, 1, kernel_initializer='he_normal', name='S-1') (skip1)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, 3, activation='relu', name='Block-2_Conv-1', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = Conv2D(128, 3, activation='relu', name='Block-2_Conv-2', padding='same') (x)\n",
    "    x = BatchNormalization() (x)\n",
    "    x = MaxPooling2D(2, strides=2, name='Pooling-2') (x)\n",
    "    skip2 = x\n",
    "    skip2 = Conv2D(1, 1, kernel_initializer='he_normal', name='S-2') (skip2)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, 3, activation='relu', name='Block-3_Conv-1', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = Conv2D(256, 3, activation='relu', name='Block-3_Conv-2', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = Conv2D(256, 3, activation='relu', name='Block-3_Conv-3', padding='same') (x)\n",
    "    x = BatchNormalization() (x)\n",
    "    x = MaxPooling2D(2, strides=2, name='Pooling-3') (x)\n",
    "    skip3 = x\n",
    "    skip3 = Conv2D(1, 1, kernel_initializer='he_normal', name='S-3') (skip3)\n",
    "    \n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-4_Conv-1', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-4_Conv-2', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-4_Conv-3', padding='same') (x)\n",
    "    x = BatchNormalization() (x)\n",
    "    x = MaxPooling2D(2, strides=2, name='Pooling-4') (x)\n",
    "    skip4 = x\n",
    "    skip4 = Conv2D(1, 1, kernel_initializer='he_normal', name='S-4') (skip4)\n",
    "    \n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-5_Conv-1', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-5_Conv-2', padding='same') (x)\n",
    "    x = BatchNormalization() (x); x = Dropout(0.2) (x)\n",
    "    x = Conv2D(512, 3, activation='relu', name='Block-5_Conv-3', padding='same') (x)\n",
    "    x = BatchNormalization() (x)\n",
    "    x = MaxPooling2D(2, strides=2, name='Pooling-5') (x)\n",
    "\n",
    "\n",
    "    x = Conv2D(4096 , (7, 7) , activation='relu' , name='Fully-Connected-1', padding='same') (x)\n",
    "    x = Conv2D(4096 , (1, 1) , activation='relu' , name='Fully-Connected-2', padding='same') (x)\n",
    "\n",
    "    \n",
    "    # Skip connections\n",
    "    x = Conv2DTranspose(512, kernel_size=2, name='Upsample_2x', strides=2) (x)\n",
    "    skip4 = MaxPooling2D(2, strides=2) (skip3)\n",
    "    add4 = add([skip4, x])\n",
    "\n",
    "    x = Conv2DTranspose(256, kernel_size=2, name='Upsample_4x', strides=2) (add4)\n",
    "    skip3 = MaxPooling2D(2, strides=2) (skip2)\n",
    "    add3 = add([skip3, x])\n",
    "\n",
    "    x = Conv2DTranspose(128, kernel_size=2, kernel_initializer='he_normal', name='Upsample_8x', strides=2) (add3)\n",
    "    x = Conv2DTranspose( 64, kernel_size=2, kernel_initializer='he_normal', name='Upsample_16x', strides=2) (x)\n",
    "    x = Conv2DTranspose( 32, kernel_size=2, kernel_initializer='he_normal', name='Upsample_32x', strides=2) (x)\n",
    "\n",
    "    x = Conv2D(1, 1, kernel_initializer='he_normal') (x)\n",
    "    x = Dropout(0.5) (x)\n",
    "\n",
    "    x = (Activation('sigmoid'))(x)\n",
    "    model = Model(img_input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f2671-6d15-48e4-aa33-738035898286",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create and Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ffb697-7c25-478b-9a07-5fb1438494f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from IPython.display import clear_output\n",
    "from skimage.io import imread\n",
    "import tensorflow as tf\n",
    "\n",
    "model = FCN8()\n",
    "\n",
    "model_path = \"./Trained_Model/Road_Model.h5\"\n",
    "\n",
    "## Function to save best model weights\n",
    "\n",
    "checkpointer = ModelCheckpoint(model_path, monitor=\"val_loss\", mode=\"min\", save_best_only = True, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "## Code block to show predictions at each epoch\n",
    "\n",
    "def show_predictions(epoch):\n",
    "    test_path1 = 'Dataset/Test_Images/11740_sat.jpg'\n",
    "    test_path2 = 'Dataset/Test_Images/112348_sat.jpg'\n",
    "    test_path3 = 'Dataset/Test_Images/115172_sat.jpg'\n",
    "\n",
    "    test_img1  = np.asarray([imread(test_path1)])\n",
    "    test_img2  = np.asarray([imread(test_path2)])\n",
    "    test_img3  = np.asarray([imread(test_path3)])\n",
    "\n",
    "    f = plt.figure(figsize = (8, 10))\n",
    "    f.suptitle(f'Epoch: {epoch}', x=0.5, y=0.02)\n",
    "\n",
    "    \n",
    "    f.add_subplot(3,2,1)\n",
    "    plt.imshow(imread(test_path1), cmap='gray')\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(3,2,2)\n",
    "    plt.imshow(model.predict(test_img1, verbose=1)[0][:,:,0], cmap='gray')\n",
    "    plt.title(\"Predicted Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(3,2,3)\n",
    "    plt.imshow(imread(test_path2), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(3,2,4)\n",
    "    plt.imshow(model.predict(test_img2, verbose=1)[0][:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(3,2,5)\n",
    "    plt.imshow(imread(test_path3), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    f.add_subplot(3,2,6)\n",
    "    plt.imshow(model.predict(test_img3, verbose=1)[0][:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    \n",
    "    plt.savefig(f'epochs/{epoch}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621ec0e-81a0-4e43-9276-41441ad5dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 56\n",
    "adam = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "\n",
    "model.compile(optimizer=adam, loss=soft_dice_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a806f5-68dd-4752-a225-18575c705c44",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Start model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63670b43-0961-44ee-b768-9b918be385e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_masks/255,\n",
    "                    validation_split = 0.1,\n",
    "                    epochs = EPOCHS,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    callbacks = [checkpointer, DisplayCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42e9f7-40c6-4784-a0d2-667a4e857a73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b70381-6092-426a-a327-f2d238d24124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "history_fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "accuracy = history_fig.add_subplot(1,2,1)\n",
    "imgplot = plt.plot(history.history['accuracy'])\n",
    "imgplot = plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Accuracy', 'Validation accuracy'], loc='upper right')\n",
    "accuracy.set_title(\"Epoch Accuracy\")\n",
    "\n",
    "loss = history_fig.add_subplot(1,2,2)\n",
    "imgplot = plt.plot(history.history['loss'])\n",
    "imgplot = plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "loss.set_title(\"Epoch Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedfd0a8-ad5b-40bf-8a55-4c63929b4a23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Get predictions from Trained Model\n",
    "> Load model from file `Road_Model.h5` and generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b9570-2c2b-4545-a11e-fba2c413cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage.io import imshow\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "model = load_model(\"./Trained_Model/Road_Model.h5\", custom_objects={'soft_dice_loss': soft_dice_loss, 'iou_coef': iou_coef})\n",
    "predictions = model.predict(test_images, verbose=1)\n",
    "thresh_val = 0.1\n",
    "predicton_threshold = (predictions > thresh_val).astype(np.uint8)\n",
    "\n",
    "\n",
    "ix = random.randint(0, len(predictions))\n",
    "num_samples = 3\n",
    "\n",
    "f = plt.figure(figsize = (12, 10))\n",
    "for i in range(1, num_samples*4, 4):\n",
    "    ix = random.randint(0, len(predictions))\n",
    "\n",
    "    f.add_subplot(num_samples, 4, i)\n",
    "    imshow(test_images[ix])\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(num_samples, 4, i+1)\n",
    "    imshow(np.squeeze(test_masks[ix][:,:,0]))\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(num_samples, 4, i+2)\n",
    "    imshow(np.squeeze(predictions[ix][:,:,0]))\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "test_path = 'Dataset/Images/100892_sat.jpg'\n",
    "mask_path = 'Dataset/Masks/100892_mask.png'\n",
    "test_img  = np.asarray([imread(test_path)])\n",
    "\n",
    "f = plt.figure(figsize = (12, 10))\n",
    "f.add_subplot(1,3,1)\n",
    "imshow(imread(test_path))\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "f.add_subplot(1,3,2)\n",
    "imshow(imread(mask_path))\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.axis('off')\n",
    "\n",
    "f.add_subplot(1,3,3)\n",
    "imshow(model.predict(test_img, verbose=1)[0][:,:,0])\n",
    "plt.title(\"Prtedicted Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb91702-1032-4601-a998-51ad7967c5f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Generate epoch prediction video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdaa233-cda7-46fb-b1ca-f3ad34210662",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf *.mp4 *.avi\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "video_name = 'video.avi'\n",
    "epochs = os.listdir('epochs')\n",
    "frame = cv2.imread('epochs/1.png')\n",
    "height, width, layers = frame.shape\n",
    "video = cv2.VideoWriter(video_name, 0, 15, (width,height))\n",
    "for i in range(1, len(epochs)):\n",
    "    video.write(cv2.imread(f'epochs/{i}.png'))\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n",
    "\n",
    "!ffmpeg -i video.avi -c:v copy -c:a copy output.mp4\n",
    "!ffmpeg -i output.mp4 -vcodec libx265 -crf 28 Epochs.mp4\n",
    "!rm output.mp4\n",
    "!printf \"Video file ready : Epochs.mp4\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
